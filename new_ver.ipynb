{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mwv1uB7mdF4R"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ==========================================\n",
        "# 1. LOAD DATA\n",
        "# ==========================================\n",
        "train = pd.read_csv(\"/kaggle/input/ai-201-b-mse-2-aiml-a/train.csv\")\n",
        "test  = pd.read_csv(\"/kaggle/input/ai-201-b-mse-2-aiml-a/test.csv\")\n",
        "\n",
        "print(train.head())\n",
        "print(train.info())\n",
        "print(train[\"NObeyesdad\"].value_counts())\n",
        "\n",
        "# ==========================================\n",
        "# 2. SEPARATE FEATURES & TARGET\n",
        "# ==========================================\n",
        "y = train[\"NObeyesdad\"]\n",
        "X = train.drop(\"NObeyesdad\", axis=1)\n",
        "\n",
        "num_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
        "cat_cols = X.select_dtypes(include=[\"object\"]).columns\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "train.isnull().sum().plot(kind='bar')\n",
        "plt.title(\"Missing Values per Column\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(x=train['NObeyesdad'])\n",
        "plt.title(\"Target Class Distribution\")\n",
        "plt.show()\n",
        "\n",
        "X[num_cols].hist(figsize=(14,10))\n",
        "plt.suptitle(\"Numeric Feature Distributions\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.heatmap(X[num_cols].corr(), cmap='coolwarm')\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# 3. HANDLE MISSING VALUES\n",
        "# ==========================================\n",
        "X[num_cols] = X[num_cols].fillna(X[num_cols].median())\n",
        "test[num_cols] = test[num_cols].fillna(X[num_cols].median())\n",
        "\n",
        "X[cat_cols] = X[cat_cols].fillna(X[cat_cols].mode().iloc[0])\n",
        "test[cat_cols] = test[cat_cols].fillna(X[cat_cols].mode().iloc[0])\n",
        "\n",
        "# ==========================================\n",
        "# 4. ENCODING\n",
        "# ==========================================\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Label encode output\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# Preprocess inputs\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
        "        (\"num\", \"passthrough\", num_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# 5. RANDOM FOREST MODEL PIPELINE\n",
        "# ==========================================\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocess),\n",
        "    (\"clf\", RandomForestClassifier(\n",
        "        n_estimators=500,\n",
        "        max_depth=20,\n",
        "        min_samples_split=2,\n",
        "        min_samples_leaf=1,\n",
        "        class_weight=\"balanced\",\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "# ==========================================\n",
        "# 6. TRAINâ€“TEST SPLIT\n",
        "# ==========================================\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y_encoded,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_encoded\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# 7. TRAIN MODEL\n",
        "# ==========================================\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ==========================================\n",
        "# 8. MODEL EVALUATION\n",
        "# ==========================================\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "print(\"Accuracy :\", accuracy_score(y_val, y_pred))\n",
        "print(\"Precision:\", precision_score(y_val, y_pred, average='macro'))\n",
        "print(\"Recall   :\", recall_score(y_val, y_pred, average='macro'))\n",
        "print(\"F1 Score :\", f1_score(y_val, y_pred, average='macro'))\n",
        "\n",
        "# ==========================================\n",
        "# 9. HYPERPARAMETER TUNING (OPTIONAL)\n",
        "# ==========================================\n",
        "# You can skip this if you're short on time.\n",
        "# Uncomment if needed.\n",
        "\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "# params = {\n",
        "#     \"clf__n_estimators\": [300, 500, 700],\n",
        "#     \"clf__max_depth\": [15, 20, 25]\n",
        "# }\n",
        "# grid = GridSearchCV(model, params, cv=3, scoring='f1_macro', n_jobs=-1)\n",
        "# grid.fit(X_train, y_train)\n",
        "# model = grid.best_estimator_\n",
        "# print(\"Best Params:\", grid.best_params_)\n",
        "\n",
        "# ==========================================\n",
        "# 10. TRAIN FULL MODEL\n",
        "# ==========================================\n",
        "model.fit(X, y_encoded)\n",
        "\n",
        "# ==========================================\n",
        "# 11. PREDICT TEST\n",
        "# ==========================================\n",
        "test_pred = model.predict(test)\n",
        "test_labels = le.inverse_transform(test_pred)\n",
        "\n",
        "# ==========================================\n",
        "# 12. FINAL SUBMISSION\n",
        "# ==========================================\n",
        "submission = pd.DataFrame({\n",
        "    \"id\": test[\"id\"],\n",
        "    \"NObeyesdad\": test_labels\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission_kiet_mse3.csv\", index=False)\n",
        "\n",
        "print(\"submission_kiet_mse2.csv CREATED SUCCESSFULLY!\")\n",
        "submission.head()"
      ]
    }
  ]
}